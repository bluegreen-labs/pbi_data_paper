#' Calculates a smoothed fit for a set of values, a span value
#' can be set / found by using optimal_span()
#'
#' @param y a vector with measurement values to smooth
#' @param x a vector with dates / time steps
#' @param span optional values to weigh the loess fit with
#' @keywords smoother, span, loess, time series
#' @export

smooth_ts <- function(
  x,
  y,
  span = 0.4
  ){
  
  # get model fit
  model <-suppressWarnings(
    try(loess(
      y ~ x,
      span = span),
      silent = TRUE
    )
  )
  
  # empty values when routine fails
  empty <- rep(NA, length(y))
  
  if(inherits(model, "try-error")){
    return(empty)
  } else {
    if(any(is.na(model$residuals))){
      return(empty)
    } else {
      return(predict(model, x))
    }
  }
}

#' Calculates the optimal span for a loess spline
#' 
#' Uses an Akaike information criterion (AIC) to balance
#' function complexity and available data.
#'
#' @param y: a vector with measurement values to smooth
#' @param x: a vector with dates / time steps
#' @param weights: optional values to weigh the loess fit with
#' @param step: span increment size
#' @keywords smoother, span, loess, time series
#' @export
#' @examples
#'
#' \dontrun{
#' # Internal function only, should not be used stand-alone.
#' 
#' l = sin(1,10,0.01)
#' l = l + runif(length(l)))
#' optimal.span(l, plot = TRUE)
#' }

# This function takes a data frame with smoothed gcc
# values and CI as input, this data is generated by
# the smooth_ts() routine or is already present in the
# downloaded phenocam file if downloaded with the default
# settings for download.phenocam()


optimal_span <- function(
  y,
  x = NULL,
  weights = NULL,
  start = 0.01,
  step = 0.01,
  label = NULL,
  plot = FALSE) {
  
  # custom AIC function which accepts loess regressions
  myAIC = function(x){
    
    if (!(inherits(x,"loess"))){
      stop("Error: argument must be a loess object")
    }
    
    # extract loess object parameters
    n = x$n
    traceL = x$trace.hat
    sigma2 = sum( x$residuals^2 ) / (n-1)
    delta1 = x$one.delta
    delta2 = x$two.delta
    enp = x$enp
    
    # calculate AICc1
    # as formulated by Clifford M. Hurvich; Jeffrey S. Simonoff; Chih-Ling Tsai (1998)
    AICc1 = n*log(sigma2) + n* ( (delta1/delta2)*(n+enp)/(delta1^2/delta2)-2 )
    
    if(is.na(AICc1) | is.infinite(AICc1)){
      return(NA)
    }else{
      return(AICc1)
    }
  }
  
  # create numerator if there is none
  if (is.null(x)){
    x = 1:length(y)
  }
  
  # return AIC for a loess function with a given span
  loessAIC = function(span){
    # check if there are weights, if so use them
    if ( is.null(weights) ){
      fit = suppressWarnings(try(loess(y ~ as.numeric(x),
                                       span=span),
                                 silent=TRUE))
    } else {
      fit = suppressWarnings(try(loess(y ~ as.numeric(x),
                                       span=span, 
                                       weights = weights),
                                 silent=TRUE))
    }
    
    # check if the fit failed if so return NA
    if (inherits(fit,"try-error")){
      return(NA)
    }else{
      return(myAIC(fit))
    }
  }
  
  # parameter range
  span = seq(start,1,by=step)
  
  # temporary AIC matrix, lapply loop
  # (instead of for loop) cleaner syntax
  tmp = unlist(lapply(span,loessAIC))
  
  # find the optimal span as the minimal AICc1 value
  # in the calculated range (span variable)
  opt.span = span[which(tmp == min(tmp,na.rm=TRUE))][1]
  
  # plot the optimization if requested
  if (plot == TRUE){
    
    par(mfrow = c(2,1))
    plot(as.numeric(x),y,
         xlab = 'value',
         ylab = 'Gcc',
         type = 'p',
         pch = 19,
         main = label)
    
    col = rainbow(length(span),alpha = 0.5)
    
    for (i in 1:length(span)){
      fit = loess(y ~ as.numeric(x),
                  span = span[i])
      lines(fit$x,
            fit$fitted,
            lwd = 1,
            col = col[i])
    }
    
    fit = loess(y ~ as.numeric(x),
                span = opt.span)
    
    lines(fit$x,
          fit$fitted,
          lwd = 3,
          col = 'black',
          lty = 1)
    
    plot(span,
         tmp,
         pch = 19,
         type = 'p',
         ylab = 'AICc1',
         col = col)
    
    abline(v = opt.span,col = 'black')
    
  }
  
  # trap error and return optimal span
  if (is.na(opt.span)) {
    return(NULL)
  } else {
    return(opt.span)
  }
}

#' Estimate the horizon location
#' 
#' Uses breakpoint detection on the blue channel to
#' detect the difference between sky and vegetation.
#' 
#' @param img single raster layer to process
#' @param penalty parameter to set the sensitivity of the changepoint
#' detection used in finding the horizon
#' @keywords region of interest selection
#' @export
#' @examples
#' # no examples yet

estimate_horizon <- function(
  img,
  penalty = 0.05
){
  
  # internal function to estimate changepoint values
  # which occur when transitioning from
  # land to sky in the image (the horizon)
  horizon <- function(x, ...){
    cpt_obj = changepoint::cpt.mean(
      x,
      method = 'PELT',
      test.stat = 'Normal',
      penalty = "Manual",
      pen.value = penalty,
      param.estimates = TRUE
    )
    horizon = length(x) - min(cpt_obj@cpts)
    return(horizon)
  }
  
  if (!grepl("Raster*",class(img)) | is.character(img)){
    stop("function needs a Raster object as input")
  }
  
  # convert to matrix
  img = raster::as.matrix(img)
  
  # fill na values
  img[is.na(img)] <- 0
  
  # in one pass convert the rasterLayer to a matrix
  # and apply() the helper function (estimating the changepoint)
  # to all columns in the matrix
  horizon_locations = apply(img, 2, horizon, penalty = penalty)
  
  # these are filters to kick out edge values
  # more can be added to refine the algorithm
  # (remove columns with no obvious breakpoint)
  horizon_locations[horizon_locations == 0] = NA
  horizon_locations[horizon_locations == nrow(img)] = NA
  
  # return the horizon locations
  return(horizon_locations)
}

#' Estimates a region of interest (ROI)
#' 
#' Uses the approximate horizon location in an image.
#'
#' @param img RGB image to process (filename or 3-layer RGB stack or brick)
#' @param padding percentage of the image width / height to pad
#' @param plot plot resulting image with all available information
#' @keywords region of interest selection
#' @export

estimate_roi <- function(
  img,
  padding = 0.1
){
  
  # verify data formats if not transform
  # to the correct data format
  if (class(img) == "character"){
    img = raster::brick(img)
  }
  
  # if possible use the bcc index
  # to find the horizon, distant pixels
  # or sky in general are always more blue
  # than those closer to the camera or containing
  # non vegetative or soil components
  if (nlayers(img) == 3){
    img = img[[3]] / sum(img)
  }
  
  # calculate some basic image statistics to be used
  # in further processing
  img_mid = ncol(img)/2
  img_width = ncol(img)
  img_height = nrow(img)
  
  # padding by 10% / 15% (values in pixels)
  padding_y = round(nrow(img) * padding * 1.5) 
  padding_x = round(ncol(img) * padding)
  
  # estimate the horizon locations
  horizon_locations = estimate_horizon(img)
  
  # I will split the image in two halfs to estimate the left and right
  # median locations / height of the horizon in the image as to compensate
  # for a slanted horizon (rather common in the images)
  left_horizon_location = median(horizon_locations[1:img_mid],na.rm = TRUE)
  right_horizon_location = median(horizon_locations[img_mid:img_width],na.rm = TRUE)
  
  # in case of missing values on one half of the image, subsitute
  if ( is.na(left_horizon_location) ){
    left_horizon_location = right_horizon_location
  }
  
  if ( is.na(right_horizon_location) ){
    right_horizon_location = left_horizon_location
  }
  
  if ( is.na(left_horizon_location) & is.na(right_horizon_location) ){
    left_horizon_location = round(img_height * 0.40) + padding_y
    right_horizon_location = round(img_height * 0.40) + padding_y
  }
  
  # in case the value of the horizon locs drops below 1/5th of the image
  # height use 1/3th as a default
  if ( left_horizon_location < round(img_height * 0.3)){
    left_horizon_location = round(img_height * 0.4) + padding_y
  }
  if ( right_horizon_location < round(img_height * 0.3)){
    right_horizon_location = round(img_height * 0.4) + padding_y
  }
  
  # in case the value of the horizon locs drops below 1/5th of the image
  # height use 1/3th as a default
  if ( left_horizon_location > round(img_height * 0.8)){
    left_horizon_location = round(img_height * 0.4) + padding_y
  }
  if ( right_horizon_location > round(img_height * 0.8)){
    right_horizon_location = round(img_height * 0.4) + padding_y
  }
  
  # I'm using the padding values and various coordinates to set the final
  # polygon coordinates
  left_x = padding_x
  right_x = ncol(img) - padding_x
  
  # format the coordinates in x-coordinate and y-coordinate vectors
  # go counter clockwise from the bottom of the image
  x = c(left_x,
        right_x,
        right_x,
        left_x)
  y = c(padding_y,
        padding_y,
        right_horizon_location - padding_y,
        left_horizon_location - padding_y)
  
  # now convert the raw coordinates into a SpatialPolygons
  # object for easier subsetting or conversion to a raster image
  roi = sp::SpatialPolygons(
    list(sp::Polygons(
      list(sp::Polygon(
        matrix(c(x,y), ncol=2, byrow=FALSE)
      )), "bb")))
  
  # return data as a SpatialPolygon object
  # can be converted to matrix or vector if needed
  return(list("roi" = roi,
              "horizon" = horizon_locations))
}

#' Reads and sizes images or raster layers
#' to a consistent format
#'
#' @param img RGB image, or raster file to process
#' @param ncols resize to a particular number of columns
#' @param nrows resize to a particular number of rows
#' if NULL the same ratio is used as set by the original ncol
#' vs. the specified ncols.
#' @keywords image preparation, image reading
#' @export

read_size <- function(
  img,
  ncols = 640,
  nrows = NULL
  ){
  
  # resizing helper function
  resize <- function(...){
    
    # return image if alread the right size
    if (ncol(img) == ncols){
      return(img)
    }
    
    # calculate number of rows
    if (is.null(nrows)){
      nrows <- round(ncols * (nrow(img) / ncol(img)))
    }
    
    # setup reference image
    reference <- raster(nrows = nrows,
                        ncols = ncols)
    crs(reference) <- NA
    
    # set new extent
    extent(reference) <- extent(img)
    
    # resample based upon reference image
    img_resampled = resample(img, reference)
    extent(img_resampled) = c(0,ncol(img_resampled),0,nrow(img_resampled))
    
    # return the image
    return(img_resampled)
  }
  
  # verify data formats if not transform
  # to the correct data format
  if (class(img) == "character"){
    img <- try(raster::brick(img))
    if(inherits(img, "try-error")){
      stop("image read error")
    }
  }
  
  # resize the original image temporarily
  # to determine it's proper orientation
  img_tmp <- resize(img = img,
                    ncols = ncols,
                    nrows = nrows)
  
  # truncate values 0 - 255
  img_tmp[img_tmp < 0] <- 0
  
  # return resized flipped image
  return(img_tmp)
}


#' Calculate phenophases from a smoothed curve
#' 
#' Will return valid values if smoothing works,
#' will return NA if it fails.
#'
#' @param date date vector 
#' @param value gcc_90 value
#' @param span smoothing value to use when estimating phenophases
#' @param long_format 
#' @keywords phenology, phenophases
#' @export

phenophases <- function(
  date,
  value,
  span = 0.4,
  long_format = TRUE
  ){
  
  if(length(value) == 0){
    return(data.frame(rising = NA,
                      falling = NA,
                      rising_lower_ci = NA,
                      rising_upper_ci = NA,
                      falling_lower_ci = NA,
                      falling_upper_ci = NA))
  }
  
  # set baseline
  date_p <- c(min(date) - 1, date,  max(date) + 1)
  value_p <- c(min(value, na.rm = TRUE), value, min(value, na.rm = TRUE))
  
  # fit a smooth curve
  model <- suppressWarnings(
    try(loess(value_p ~ date_p, span = 0.4), silent = TRUE)
  )
  
  # range over which to interpolate the smoothed fit
  t <- min(date):max(date)
  
  # if the model is valid, predict missing locations
  # between start and finish of the acquisitions
  ts <- suppressWarnings(try(predict(model, t, se = TRUE), silent = TRUE))
  
  if(inherits(ts, "try-error")){
    return(data.frame(rising = NA,
                      falling = NA,
                      rising_lower_ci = NA,
                      rising_upper_ci = NA,
                      falling_lower_ci = NA,
                      falling_upper_ci = NA
                      ))
  }
  
  # scale between 0 and 1
  values <- scales::rescale(ts$fit, to = c(0, 1))
  amp <- max(ts$fit, na.rm = TRUE) - min(ts$fit, na.rm = TRUE)
  
  values_upper <- values + (ts$se.fit / amp)
  values_lower <- values - (ts$se.fit / amp)
  
  # find the max location on the curve
  loc <- t[which(values == max(values, na.rm = TRUE))]
  
  # rising
  rising <- as.Date(t[which(values >= 0.73 & t < loc)[1]],
                         origin = "1970-01-01")
  rising_upper_ci <- as.Date(t[which(values_upper >= 0.73 & t < loc)[1]],
                         origin = "1970-01-01")
  rising_lower_ci <- as.Date(t[which(values_lower >= 0.73 & t < loc)[1]],
                             origin = "1970-01-01")
  
  falling <- as.Date(t[which(values <= 0.83 & t > loc)[1]],
                          origin = "1970-01-01")
  falling_upper_ci <- as.Date(t[which(values_upper <= 0.83 & t > loc)[1]],
                     origin = "1970-01-01")
  falling_lower_ci <- as.Date(t[which(values_lower <= 0.83 & t > loc)[1]],
                     origin = "1970-01-01")
  
  # When CI dates equal the estimated phenology date pad by
  # standard 1 day uncertainty (rounding error)
  if(!is.na(falling_lower_ci) & !is.na(falling)){
    if(falling_lower_ci == falling){
      falling_lower_ci <- falling_lower_ci - 1
    }
  }
  
  if(!is.na(falling_upper_ci) & !is.na(falling)){
    if(falling_upper_ci == falling){
      falling_upper_ci <- falling_upper_ci + 1
    }
  }
  
  if(!is.na(rising_lower_ci) & !is.na(rising)){
    if(rising_lower_ci == rising){
      rising_lower_ci <- rising_lower_ci + 1
    }
  }
  
  if(!is.na(rising_upper_ci) & !is.na(rising)){
    if(rising_upper_ci == rising){
      rising_upper_ci <- rising_upper_ci - 1
    }
  }
  
  # format the output, depending on what is requested
  # only the dates or the source time series as well
  if(!long_format){
    return(data.frame(rising = rising,
                      falling = falling,
                      rising_lower_ci = rising_lower_ci,
                      rising_upper_ci = rising_upper_ci,
                      falling_lower_ci = falling_lower_ci,
                      falling_upper_ci = falling_upper_ci))
  }else{
    return(data.frame(
               date = as.Date(t, origin = "1970-01-01"),
               smooth_gcc_90 = values,
               smooth_gcc_90_lower_ci = values_lower,
               smooth_gcc_90_upper_ci =values_upper,
               rising = rising,
               falling = falling,
               rising_lower_ci = rising_lower_ci,
               rising_upper_ci = rising_upper_ci,
               falling_lower_ci = falling_lower_ci,
               falling_upper_ci = falling_upper_ci))
  }
}

